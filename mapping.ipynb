{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from rdflib import Graph, Namespace, Literal, FOAF, RDF, XSD\n",
    "# Modulo creado por nosotros\n",
    "import wikidata_requests as wkd_req"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los archivos en la carpeta data con la estructura AMR_taxid_*.txt serán los convertidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\AMR_taxid_1280.txt',\n",
       " 'data\\\\AMR_taxid_1639.txt',\n",
       " 'data\\\\AMR_taxid_1773.txt',\n",
       " 'data\\\\AMR_taxid_197.txt',\n",
       " 'data\\\\AMR_taxid_28901.txt',\n",
       " 'data\\\\AMR_taxid_573.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = 'data/AMR_taxid_*.txt'\n",
    "list_files = glob.glob(files)\n",
    "list_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos todos los archivos y preprocesamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicated rows.\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(\n",
    "            file_path,\n",
    "            sep='\\t',\n",
    "            usecols=[\n",
    "                'pathogen_name',\n",
    "                'taxonid',\n",
    "                'ARG_name',\n",
    "                'frequency',\n",
    "                'antibiotic_name',\n",
    "                'drugclass'\n",
    "            ]\n",
    "        ) for file_path in list_files\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f'There are {df.duplicated().sum()} duplicated rows.')\n",
    "if duplicates:\n",
    "    print('Removing them...')\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "# Drop files where there isn't either antibiotic_name or drugclass\n",
    "rows_to_drop = df[df.drugclass.isna() & df.antibiotic_name.isna()].index\n",
    "df.drop(rows_to_drop, inplace=True)\n",
    "\n",
    "# If there isn't an antibiotic_name, it means it is inmune to the whole drugclass\n",
    "df.fillna({'antibiotic_name': df.drugclass}, inplace=True)\n",
    "\n",
    "# Drugclass is not needed anymore\n",
    "df.drop(columns='drugclass', inplace=True)\n",
    "\n",
    "# df.to_csv('all_ARM_taxid.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el grafo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph()\n",
    "dat = Namespace('https://junjingw.github.io/bacteria-ontologia/data/')\n",
    "ont = Namespace('https://junjingw.github.io/bacteria-ontologia/ontology#')\n",
    "\n",
    "# Counters for the unique identifiers for each entity\n",
    "n_bac = 1\n",
    "n_arg = 1\n",
    "n_mut = 1\n",
    "n_ant = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enlazamos los datos y los añadimos al grafo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria_to_uri = dict()\n",
    "bacterias_df = df[['pathogen_name', 'taxonid']].drop_duplicates().set_index('pathogen_name')\n",
    "for bacteria in bacterias_df.index:\n",
    "    # Extract linked data\n",
    "    bacteria_uri = dat[f'bac{n_bac}']\n",
    "    taxonid = bacterias_df.taxonid[bacteria]\n",
    "    bacteria_to_uri[bacteria] = bacteria_uri\n",
    "    \n",
    "    # Add corresponding triples\n",
    "    g.add((bacteria_uri, RDF.type, ont.Bacteria))\n",
    "    g.add((bacteria_uri, FOAF.name, Literal(bacteria)))\n",
    "    g.add((bacteria_uri, ont.taxonId, Literal(taxonid, datatype=XSD.integer)))\n",
    "    \n",
    "    n_bac += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "antibiotic_to_uri = dict()\n",
    "for ant in df.antibiotic_name.str.split(',').explode().unique():\n",
    "    # Extract linked data\n",
    "    antibiotic_uri = dat[f'ant{n_ant}']\n",
    "    antibiotic_to_uri[ant] = antibiotic_uri\n",
    "    \n",
    "    # Add corresponding triples\n",
    "    g.add((antibiotic_uri, RDF.type, ont.Antibiotic))\n",
    "    g.add((antibiotic_uri, FOAF.name, Literal(ant)))\n",
    "    \n",
    "    n_ant += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_to_uri = dict()\n",
    "arg_df = df[['ARG_name', 'antibiotic_name']].set_index('ARG_name').antibiotic_name.str.split(',').explode()\n",
    "for arg in arg_df.index.unique():\n",
    "    # Extract linked data\n",
    "    arg_uri = dat[f'arg{n_arg}']\n",
    "    arg_to_uri[arg] = arg_uri\n",
    "    \n",
    "    # Add corresponding triples\n",
    "    g.add((arg_uri, RDF.type, ont.ARG))\n",
    "    g.add((arg_uri, FOAF.name, Literal(arg)))\n",
    "    \n",
    "    # Add antibiotic resistance information\n",
    "    if isinstance(arg_df[arg], str):\n",
    "        g.add((arg_uri, ont.resistantTo, antibiotic_to_uri[arg_df[arg]]))\n",
    "    else:\n",
    "        for ant in arg_df[arg].unique():\n",
    "            g.add((arg_uri, ont.resistantTo, antibiotic_to_uri[ant]))\n",
    "            \n",
    "    n_arg += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_to_uri = dict()\n",
    "mut_df = df.drop(columns=['taxonid', 'antibiotic_name'])\n",
    "for mutation in mut_df.index:\n",
    "    # Extract linked data\n",
    "    mutation_uri = dat[f'mut{n_mut}']\n",
    "    bacteria_uri = bacteria_to_uri[mut_df.pathogen_name[mutation]]\n",
    "    arg_uri = arg_to_uri[mut_df.ARG_name[mutation]]\n",
    "    frequency = mut_df.frequency[mutation]\n",
    "    mut_to_uri[mutation] = mutation_uri\n",
    "    \n",
    "    # Add corresponding triples\n",
    "    g.add((mutation_uri, RDF.type, ont.Mutation))\n",
    "    g.add((mutation_uri, ont.frequency, Literal(frequency, datatype=XSD.float)))\n",
    "    g.add((mutation_uri, ont.linkedToARG, arg_uri))\n",
    "    g.add((bacteria_uri, ont.hasMutation, mutation_uri))\n",
    "    \n",
    "    n_mut += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos _reconciling_ con wikidata para obtener los signos (síntomas, causas y efectos) de cada patógeno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = bacterias_df.reset_index()\n",
    "temp['signs'] = temp.pathogen_name.apply(wkd_req.get_qualifier).apply(wkd_req.get_signs)\n",
    "bacterias_df = temp.set_index('pathogen_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_signs_df = bacterias_df.signs.explode()\n",
    "for bacteria in exploded_signs_df.index.unique():\n",
    "    signs = exploded_signs_df[bacteria]\n",
    "    if isinstance(signs, str):\n",
    "        g.add((bacteria_to_uri[bacteria], ont.hasSign, Literal(signs)))\n",
    "    else:\n",
    "        for sign in signs:\n",
    "            g.add((bacteria_to_uri[bacteria], ont.hasSign, Literal(sign)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos todos estos datos en nuestro triplestore (a esta escala será simplemente un archivo turtle):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N784fdef78afa41668699973cd1a16fcf (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize('data.ttl', format='turtle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
